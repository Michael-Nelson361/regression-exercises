{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75239826-9725-426f-9948-e7fc78223148",
   "metadata": {},
   "source": [
    "Do your work for these exercises in a jupyter notebook named `scaling`. Use the zillow dataset you acquired and prepped in previous lesson. Once you are finished, you may wish to repeat the exercises on another dataset for additional practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d78e37-9a71-4ac6-866c-ee5015ad119c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import personal libraries\n",
    "import wrangle as w\n",
    "import explore as e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e06254f-6ee8-4b9a-bc3f-040c4dbd7c13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import itertools -> iterations\n",
      "import time -> time and date work\n",
      "from tqdm import tqdm -> progress bars on for loopsimport pandas as pd -> large scale database work\n",
      "import numpy as np -> advanced numerical work\n",
      "import matplotlib.pyplot as plt -> plotting work\n",
      "import seaborn as sns -> advanced and intuitive plotting\n",
      "from scipy import stats -> statistical work\n",
      "from pydataset import data -> list of datasets\n",
      "import os -> operating system work\n",
      "import warnings -> getting rid of pesky warnings\n",
      "from sklearn import metrics -> model metrics\n",
      "from sklearn.impute import SimpleImputer -> dynamic value filling\n",
      "from sklearn.model_selection import train_test_split -> splitting datasets\n",
      "from sklearn.tree import DecisionTreeClassifier, plot_tree -> DT modeling\n",
      "from sklearn.neighbors import KNeighborsClassifier -> KNN modeling\n",
      "from sklearn.ensemble import RandomForestClassifier -> RF modeling\n",
      "from sklearn.linear_model import LogisticRegression -> LR modeling\n",
      "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler -> scaling work\n"
     ]
    }
   ],
   "source": [
    "# select libraries to pull\n",
    "w.print_libs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44d1935e-af24-44eb-a03f-1e8250bf066b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import additional libraries\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb20ccd-d19f-4f29-bb89-21255d72437a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from file...\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "train,validate,test = w.wrangle_zillow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "365af2ff-508a-47dd-97ca-2e43a21c79f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nunique</th>\n",
       "      <th>dtypes</th>\n",
       "      <th>isnull</th>\n",
       "      <th>1511532</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>17</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>37</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_area</th>\n",
       "      <td>9540</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>2793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_value</th>\n",
       "      <td>446402</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>541300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearbuilt</th>\n",
       "      <td>149</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxamount</th>\n",
       "      <td>707961</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>6623.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fips</th>\n",
       "      <td>3</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>6037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county</th>\n",
       "      <td>3</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                nunique   dtypes  isnull      1511532\n",
       "bedrooms             17    int64       0            3\n",
       "bathrooms            37  float64       0          3.0\n",
       "property_area      9540    int64       0         2793\n",
       "property_value   446402    int64       0       541300\n",
       "yearbuilt           149    int64       0         1941\n",
       "taxamount        707961  float64       0      6623.92\n",
       "fips                  3    int64       0         6037\n",
       "county                3   object       0  Los Angeles"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data\n",
    "w.df_info(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df5d31f-7beb-4d71-a006-eca2390dec8e",
   "metadata": {},
   "source": [
    "1. [ ] Apply the scalers we talked about in this lesson to your data and visualize the results for the unscaled and scaled distribution ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43a3cafb-a4a8-40a0-bbd8-f3c1c81e14ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c87b2fc-8449-493a-8b15-d14b8dcab368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply the StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c4d315-c56e-4c8a-89cc-e29843f3e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc432a5-bae2-4e5c-a51f-9730bca7cc6c",
   "metadata": {},
   "source": [
    "2. [ ] Apply the `.inverse_transform` method to your scaled data. Is the resulting dataset the exact same as the original data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f8df9-8419-4e95-afe6-36ee1a627dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f19262a9-deef-4a65-9827-3bd99d7d67f9",
   "metadata": {},
   "source": [
    "3. [ ] Read the documentation for sklearn's `QuantileTransformer`. Use `normal` for the `output_distribution` and apply this scaler to your data. Visualize the result of your data scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3db075-65fe-48b6-9af2-6542807466d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c32f27c-fffa-497c-9ad3-217704466f3d",
   "metadata": {},
   "source": [
    "4. [ ] Use the `QuantileTransformer`, but omit the `output_distribution` argument. Visualize your results. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a966a-547f-4108-a818-f61fba7413e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f01d87b5-fb38-468f-80e8-4a9d864781f0",
   "metadata": {},
   "source": [
    "5. [ ] Based on the work you've done, choose a scaling method for your dataset. Write a function within your `prepare.py` that accepts as input the train, validate, and test data splits, and returns the scaled versions of each. Be sure to only learn the parameters for scaling from your training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b76f62b-3f5d-4c0c-8f48-09e9a50bd7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
